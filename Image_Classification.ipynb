{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6972d835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Before using any library install it first - !pip install \"your library name\"\n",
    "\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import warnings\n",
    "# from keras.preprocessing.image import load_img\n",
    "# warnings.filterwarnings('ignore')\n",
    "# import os\n",
    "# import tqdm\n",
    "# import random\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dceca62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PetImages directory to collect file paths and assign labels for cats (0) and dogs (1)\n",
    "input_path = []\n",
    "label = []\n",
    "\n",
    "for i in os.listdir(\"PetImages\"):\n",
    "  for path in os.listdir(\"PetImages/\"+i):\n",
    "    if i == \"Cat\":\n",
    "      label.append(0)\n",
    "    else:\n",
    "      label.append(1)\n",
    "    input_path.append(os.path.join(\"PetImages\",i,path))\n",
    "print(input_path[0],label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a694fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(label)\n",
    "len(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd86949",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['images'] = input_path\n",
    "df['label'] = label\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07672b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,25))\n",
    "temp = df[df['label']==1]['images']\n",
    "start = random.randint(0,len(temp))\n",
    "files = temp[start:start+25]\n",
    "\n",
    "for index, file in enumerate(files):\n",
    "  plt.subplot(5,5,index+1)\n",
    "  img = load_img(file)\n",
    "  img = np.array(img)\n",
    "  plt.imshow(img)\n",
    "  plt.title(\"Dogs\")\n",
    "  plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9434e657",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,25))\n",
    "temp = df[df['label']==0]['images']\n",
    "start = random.randint(0,len(temp))\n",
    "files = temp[start:start+25]\n",
    "\n",
    "for index, file in enumerate(files):\n",
    "  plt.subplot(5,5,index+1)\n",
    "  img = load_img(file)\n",
    "  img = np.array(img)\n",
    "  plt.imshow(img)\n",
    "  plt.title(\"cats\")\n",
    "  plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d8869c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete db files\n",
    "for i in df['images']:\n",
    "  if '.jpg' not in i:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fed797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets delete the currupted images\n",
    "import PIL\n",
    "list = []\n",
    "for image in df['images']:\n",
    "  try:\n",
    "    img = PIL.Image.open(image)\n",
    "  except:\n",
    "    list.append(image)\n",
    "list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614428ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete df files\n",
    "df = df[df['images']!= 'PetImages/Dog/11702.jpg']\n",
    "df = df[df['images']!= 'PetImages/Cat/666.jpg']\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694d73f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['label'].astype('str')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee64577",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b630484b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained binary classification model (cat vs. dog)\n",
    "model = load_model('final_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528dc2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load and split the dataset\n",
    "\n",
    "# df = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8f0b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create image data generators\n",
    "\n",
    "train_generator = ImageDataGenerator(\n",
    "    rescale=1./255, rotation_range=40, shear_range=0.2,\n",
    "    zoom_range=0.2, horizontal_flip=True, fill_mode='nearest'\n",
    ")\n",
    "val_generator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_iterator = train_generator.flow_from_dataframe(\n",
    "    train, x_col='images', y_col='label', target_size=(128, 128),\n",
    "    batch_size=512, class_mode='binary'\n",
    ")\n",
    "val_iterator = val_generator.flow_from_dataframe(\n",
    "    test, x_col='images', y_col='label', target_size=(128, 128),\n",
    "    batch_size=512, class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd72cc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Build the model\n",
    "model = Sequential([\n",
    "    Conv2D(16, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPool2D((2, 2)),\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    MaxPool2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPool2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a47f41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Define callbacks\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath='best_model.keras', monitor='val_accuracy',\n",
    "    save_best_only=True, mode='max', verbose=1\n",
    ")\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_accuracy', patience=5, mode='max', restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b7361b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Train the model\n",
    "history = model.fit(\n",
    "    train_iterator, epochs=15, validation_data=val_iterator,\n",
    "    callbacks=[checkpoint_callback, early_stopping_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f0ffb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Save the final model\n",
    "model.save('final_model.keras')\n",
    "print(\"Final model saved as 'final_model.keras'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9e3f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(val_iterator)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bff87bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract accuracy and loss values from history\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(len(acc))  # Number of epochs\n",
    "\n",
    "# Plot Training & Validation Accuracy\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(epochs, acc, 'b', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n",
    "plt.title(\"Training vs Validation Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot Training & Validation Loss\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
    "plt.title(\"Training vs Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Show plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ec29df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install mtcnn\n",
    "# !pip install opencv-python\n",
    "# !pip install tensorflow\n",
    "# !pip install --upgrade setuptools\n",
    "# !pip install --upgrade backports.tarfile\n",
    "\n",
    "from mtcnn import MTCNN\n",
    "\n",
    "# Test MTCNN\n",
    "detector = MTCNN()\n",
    "print(\"MTCNN loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27e4735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now i am going to deploy my img classification model using Gradio library\n",
    "# !pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cef290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.keras.models import load_model\n",
    "from mtcnn import MTCNN  # For human face detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecda2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained binary classification model (cat vs. dog)\n",
    "model = load_model('final_model.keras')\n",
    "\n",
    "# Initialize MTCNN for human face detection\n",
    "face_detector = MTCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14c3225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect human faces\n",
    "def detect_human_face(image):\n",
    "    # Convert PIL image to numpy array\n",
    "    image_array = np.array(image)\n",
    "    # Detect faces using MTCNN\n",
    "    faces = face_detector.detect_faces(image_array)\n",
    "    return len(faces) > 0  # Return True if at least one face is detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4757c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to classify cats and dogs\n",
    "def classify_cat_dog(image):\n",
    "    # Preprocess the image for the binary classification model\n",
    "    image = image.resize((128, 128))  # Resize to match model input size\n",
    "    image = np.array(image)  # Convert to numpy array\n",
    "    image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
    "    image = image / 255.0  # Normalize pixel values\n",
    "\n",
    "    # Perform model inference\n",
    "    predictions = model.predict(image)\n",
    "    dog_prob = predictions[0][0]  # Probability of being a dog\n",
    "    cat_prob = 1 - dog_prob  # Probability of being a cat\n",
    "\n",
    "    # Determine the classification result\n",
    "    if dog_prob > 0.5:\n",
    "        return f\"A Dog (Confidence: {dog_prob:.2f})\"\n",
    "    else:\n",
    "        return f\"A Cat (Confidence: {cat_prob:.2f})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee588141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to handle image classification\n",
    "def classify_image(image):\n",
    "    # Convert Gradio input image to PIL format\n",
    "    image = Image.fromarray(image.astype('uint8'))\n",
    "\n",
    "    # Step 1: Check for human faces\n",
    "    if detect_human_face(image):\n",
    "        return \"I'm not trained to classify human faces.\"\n",
    "\n",
    "    # Step 2: Classify the image as either a cat or a dog\n",
    "    return classify_cat_dog(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e756d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=classify_image,  # Function to call\n",
    "    inputs=\"image\",     # Input type\n",
    "    outputs=\"text\",     # Output type\n",
    "    title=\"Image Classification\",  # Title of the interface\n",
    "    description=\"Upload an image, and the model will classify it as Cat, Dog, or Human.\"\n",
    ")\n",
    "\n",
    "# Launch the interface\n",
    "iface.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
